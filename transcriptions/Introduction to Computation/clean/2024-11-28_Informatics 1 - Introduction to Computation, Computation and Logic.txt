Okay.
Thank you all for coming.
I hope it's worth your while.
, so I said I would fulfil the promise to
tell those of you who wanted to know about it.
Something about how these things were done a few hundred
years ago.
So these are actually slides I prepared for my institute
lunchtime talk.
So they're not originally aimed at you, but that's okay
because there's only a little bit that is a bit
more formal.
So I started by explaining to my colleagues who generally
don't know syllogisms what a syllogism is in modern notation.
And since it's been a few weeks since we've done
them, this should be familiar, but maybe the reminder is
helpful.
So we talked about a universe and predicates, and we
defined entailment which is basically a disguised universal implication.
And we had the notion of categorical proposition from Aristotle,
which was one of these things with a entails B,
not B or a does not entail not B or
whatever.
And we said we can flip things around.
And we introduced the syllogism.
We didn't write it down quite this.
So this is just annoying mathematician abstraction.
But it means exactly what we wrote down.
I'm just using a few symbols because I want to
later.
And then I explain to them how we can derive
all the sound syllogisms.
So that's what we did during the course.
We said that we have this basic sound syllogism, which
was called Barbara, for reasons that we're now going to
understand, and that all the others can be got from
Barbara by doing one of four operations.
So we can substitute for predicates by other predicates, or
by negated predicates.
We had double negation cancellation.
We had contra position on sequence flip and negate, and
we had contra position on rules flip and negates.
, have you all learned your Greek alphabet?
How many of you know what this letter is and
are not Greek?
Capital Epsilon okay in there just because I Capital
Epsilon as a letter.
, so what did Aristotle do?
Aristotle did not have this notation.
So he talked about, as we said, the notion of
a universal affirmative proposition.
So this is translating Greek into English but not doing
anything else.
And he didn't actually express it as, , every Greek
is human.
He expressed it as human is true of every Greek.
And in medieval times they introduced a handy symbolic abbreviation
for this.
Curiously, the medieval logicians were quite happy to use Latin
letters rather than Greek letters.
, so they wrote A of a B for the
universal affirmative a wholes of every b, we would write
it as every b is a And they introduced a
similar abbreviation E for the negative no B is a
or in Aristotle's phrasing, a holes of no b, and
then the particular ones.
These are what we call the existential ones I, a,
b is the particular affirmative a holds of some b,
so there is some b that of which a holds
and o is the negative.
There is some B of which A fails to hold.
And the way you're supposed to remember these magic things
a e I o r that afirmo has a and
I in it and means I affirm and nego has
e and o in it, and means I deny, which
I'm sure is very helpful.
And there was a lot of terminology about this.
And if you learned all this stuff until quite recently,
you had to learn all this terminology.
I think it's much easier in modern logic.
So these a and B.
So this is things humans Greek mortal.
We call them predicates.
They were called terms in the premodern logic.
And confusingly a that is , what is a human
or mortal is the predicate, and B that is Greeks
or mortals, Greeks or humans are the subject.
So here predicate and subject are being used in the
linguistic grammatical sense.
If you did grammatical analysis in any remotely formal sense,
you talked about, , the dog bit the man.
The dog is the subject of the sentence and bit
the man is the predicate of the sentence.
So that's how the the terminology was used.
, we also remember mentioned at some point that Aristotle
didn't believe in talking about fiction, and that means he
had the existential assumption.
This is something I have to explain to my colleagues,
because we don't do it now.
And we saw at some point that that meant that
A holds of every B and A fails of some
B are not actually the negatives of each other as
they are in modern logic and the way we did
it.
But for Aristotle, they weren't.
They were two different statements.
So that was a bunch of terminology.
Then there's yet more terminology.
Again, this is translated from Greek into English.
So Aristotle then talked about different styles of argument.
And in English we talk about different figures of argument.
So a figure is more or less what we've been
calling a syllogism.
It's a premise two premises and a conclusion.
And these things have the property that the two premises
share something.
So in the standard example, the two premises share human
and human is the subject of the first and the
predicate of the second.
So we have a major premise, as it's called, containing
the predicate or predicate of the conclusion.
So in the conclusion the predicate is mortal.
So the major premise is the one that contains the
mortal predicate.
And the minor premise is the one that contains the
others.
So if you're learning this in traditional notation, you look
at the standard, the initial example.
All humans are mortal, blah blah blah, and you can
label all the bits in it as being subject, predicate,
and whether they belong to the middle term or the
major term or whatever.
And just for good measure, the terms within the predicate.
So also given mid-major labels.
So I find it extremely confusing and I just can't
remember it.
So I do not remember it.
I have no need to remember it and nor have
you, but once upon a time you would have had
to remember it.
So why is he talking about figures?
Because arguments have different structures.
So if you think about Barbara, Barbara says all humans
are mortal, all mortals, and so all Greeks are mortal
and therefore, no, sorry, all Greeks are human and therefore
all Greeks are mortal.
If you write that in the medieval notation, then the
shared term looks that.
So figures of the so-called first time kind are Barbara
figures.
And then there are several other ways you could permute
the terms, so the shared term might be in the
first position in each one, or it might be in
the last position, or it might be at the end.
So here we have.
The first kind is where the shared term is at
the end of the second and the beginning of the
first term.
The fourth kind is when the shared term is at
the beginning of the first and the beginning of the
second.
Now, we were pretty lax about swapping things around.
We said, it doesn't matter what order you put things
in too often, but remember, these are actually categorical statements,
so the order matters.
, very confusingly, Aristotle didn't recognise this kind of argument
as a different kind of figure.
He treated it as a special kind of first figure.
And I tried to understand that, and I read people's
analysis of it, and I still don't know what he
was doing there.
So there was definitely some confusion going on.
Now all the way through this course, we have been
misusing the term syllogism okay.
Because actually for Aristotle, a syllogism was something that was
sound.
So in Aristotle's terminology, what we have been calling a
syllogism was actually called a figure, the Greek for figure.
And what we have been calling a sound syllogism was
what he called a syllogism.
I'm not quite sure where that shift in terminology happened.
I think it happened between the medieval era and modern
logic, but it's what we have at the moment.
So we've got figures.
That is what we were calling syllogisms, and we have
to decide whether they're sound or unsound.
When we looked at Barbara, we stared at it and
said, that's obviously sound, right?
Okay.
Because it's implication and transitivity of implication, blah blah blah
blah.
It's obviously sound.
Or you can prove by prove it by truth tables.
If you believe truth tables are sound.
, Aristotle did the same.
So for any syllogism that was in what he called
the first figure, that is where the shared term of
the premises looks this.
the Barbara style, he said each one is either
self-evidently sound or self-evidently unsound according to whether it was
or not.
Then for the second, third and variance of the fourth,
he did the same kind of argument that we used
to determine whether they were sound.
But because he had the existential assumption, he had some
other things he could do.
So if you remember, that's the affirmative.
That's the particular affirmative.
So this is some B is a and this is
some A's.
B if you remember the existential statement is symmetrical.
If some A's.
B then it follows that some b is a.
So he had that symmetry rule.
Similarly with the negative one negative universal because he had
the existential assumption, he could also say that if I
know all B or A, then I know that some
A's b.
, he had contradiction.
So he was able to do proof by contradiction.
And there was a thing called thesis.
Which was an argument that is not quite understood and
is generally believed probably to be wrong, but he only
used it when it gave the right answer, which is
a strategy that may be familiar to some of you
until you found a better way to do it.
It's something that mathematicians.
So when mathematicians fall into error, usually the error is
usually using a faulty argument argument to prove a correct
conclusion.
We don't often prove things that are false, although it
does happen, but we quite often prove things that are
true without correctly proving them.
And for unsound things he had the notion of counterexamples,
so it was all quite familiar in the way that
you've learned.
It's just the notation was much harder to deal with.
Then what happened?
Well, in Europe, the period between about 414 hundred was
a pretty dodgy period for academics because there was a
lot of stuff going on with the fall of empires
and the rise of empires and various invasions from other
places.
So the early, early, what do we call the first
millennium and early mid to late first millennium was a
quiet time for logic in Europe, and logic was more
happening in the Arab world and it wasn't really spreading
to Europe very fast.
By the early second millennium, then medieval logicians in Europe
were partly finding out about what's been going on in
the Arab world and also developing it.
So Avicenna is a Persian logician who wrote in Arabic
for mathematical stuff.
These are European logicians.
All of them are pretty famous.
But Boethius was very famous as a philosopher.
Abelard.
Anybody heard of Abelard?
Very tragic story.
Go and look him up.
William of Ockham.
Who's heard of Occam's razor?
This.
Is that William and John Burdon famous fable called Burdon's
ass as in donkey.
Because we speak English.
So all these people took Aristotle's theory and they refined
it and developed it and tidied up a bit.
And one of the things they tidied it up was
the way Aristotle had said, A belongs to every B,
and they changed it to B, every B is A.
There was a lot of other stuff going on.
So Aristotle did.
Aristotle tried to do something that we now call modal
logic.
Modal logic is about reasoning about what must be true
and what may be true.
So it's the rules.
So if it must be the case that it must
be the case, then it must be the case.
And you have rules that.
So the rules for that kind of logic are different.
Aristotle tried to do an analysis of this kind of
logic.
And essentially he failed.
So I have tried to read it in translation, obviously,
and it makes no sense.
I've read other people who are much better at this,
and they say it doesn't make much sense either.
But Borodin, who must have been an incredibly clever person,
took this mess and developed it into a fairly coherent
explanation of the logics of must and maybe and it
was probably one can't quite tell, but it was very
probably essentially the same as the logic we now call
S5, which was invented in the 1950s by Steven Carlini,
who was on the slide of the last lecture.
So Borodin was approximately 500 years ahead of his time,
which is quite impressive.
, however, your average logic student probably didn't study modal
logic, but they did study syllogisms and they had this
horrible terminology and they didn't have our nice modern notation.
So how did they learn which syllogisms were sound?
Well, they learned it by memorising this rhyme.
So.
How you pronounce this depends on which bit of Europe
you were and when in Europe you were.
.
I won't attempt to do what a pre-World War one.
English.
Well, okay, I will attempt to do what in pre-World
War one English logician would have done.
So before the first war, a student learning this in
England would have said something Barbara Hillier and Derry
Theriault, Barry Lipton, sealants de bitties, pasma and so on.
, nowadays, we wouldn't do that if you were an
Italian.
medieval Italian logician, then you would have said Barbara and
Daddy.
Fatty or bada lepton.
And that would work for most of Europe, except you
might say, salad.
And instead of children, or in some places you might
even say salad and but probably not.
But I mean, it doesn't have any particular structure to
it, but it's got a bit of a jingle to
it, and it's not too hard to learn by heart
if you want to do so.
And the reason you do this is that each of
these words, which are almost mostly nonsense words, but not
all of them, they name one of the syllogisms, and
they not only name it, they tell you what it
is and how to prove that it sound.
So how does this work?
We'll look at Barbara.
Excellent.
So the first three vowels of Barbara are a, a,
a.
And that tells you what kind of the categorical propositions
are, because a is the universal affirmative.
So we know that this is all, all, all.
And then the first letter is b, c, d or
f.
And that tells you what the shape of the proposition
is in Aristotle's term.
First figure.
Second figure.
Third figure.
Fourth figure.
So Barbara has the shape a b b c a
c.
So that gives us the shape that we know and
love for Barbara.
And we saw Brent somewhere in the lectures.
So if you go back you can check that it
had that shape.
and then so that tells you what the syllogism
is.
And then some of the other letters tell you how
to derive the ones that are not obvious.
So here is one Dorothy.
Says if all ASC and all b a c, then
some a is.
B this is not true for us.
This needs the existential assumption.
So this is one that was true for Aristotle.
And this letter p here after the r.
So it would be T but dart up t.
The p tells you that there's an instantiation of a
universal thing to an existential thing.
Because this is Aristotle.
If you know that every C is B, you know
that some b is C.
So that tells you how to prove that and you
end up with daddy.
Another thing that you can do.
So you might be able to swap the subject and
predicate.
So for the existential ones every a is so a
some A's B is equivalent to some B is A
no, a is B is equivalent to no, b is
a.
So with data C, then you need to swap b
and c here and you get something that is Dari
again.
Sometimes you want to swap the premises.
So when we did syllogisms, we just assumed we could
swap premises because it just made sense.
But they had this terminology of major premise and minor
premise.
So you have to have an explicit rule that says
you can swap two premises around.
So the letter M told that you could do that.
So chemistry is the m between the r a and
the E tells you that you can reduce this to
something with an E and an A, which is Callard
and Killara and I'm saying on time.
And they had contra position as well.
So the letter C tells you that whatever this syllogism
is so barocco which I think we also had in
one of the exercises.
So that says every A is B and no A
is C tells you that no B is C that
can be got from Barbara by contra position.
So if you choose to and some of you may
choose to, if you could go back to the table
of valid syllogisms that we had and check against the
rhyme and see how this works.
.
To me, learning this stuff is a lot harder than
working every one of them out from first principle each
time you need to do it.
But the, , native intelligence of logic students probably varied
as much as it does today, and they had to
pass exams too.
And their exams were all oral, so they had to
be able to do stuff quite fast.
, so that was what medieval syllogisms are and how
the notation worked.
And this is what you would have been doing 500
years ago if you were studying this stuff.
And I'll just sort of finish this first half of
today with something that should have should not have surprised
me, but did.
So there was a guy called Jakob Handel in German
or Jacobo Gallus in Latin, and he was actually from
Slovenia, what is now Slovenia.
It wasn't then, and he was a composer and an
organist, and he wrote a lot of religious music, and
he also a lot of wrote a lot of secular
music, including madrigals.
And at some point he must have studied logic.
In fact, I know he studied logic, so he studied
logic at some point, and at some point he had
to learn that rhyme.
And well, it's got a nice jingle to it.
So he wrote a madrigal which sets the nice jingle
to music.
I happen to medieval music, especially madrigals, so I
was quite pleased by this.
So let me get the rhyme back and then I
will attempt to.
See if this comes out.
It may be quite loud at the beginning.
I will reduce the volume if it's deafening.
But it isn't deafening.
So let me.
Go back and start again.
Because that was very far from deafening.
Barbara, the knowledge that your body is an ordinary can
be modified to love stop it.
Stop it!
Stop it!
This office will prepare us for tomorrow.
Tomorrow is the summer.
For more reasons.
For more reasons.
Tomorrow.
This is the law, says I.
It says.
And he compares his promised rest passing over.
No offence in the world, but of all the cinnamon
rolls of cinnamon.
Roll down.
Shut up, shut up!
The Lord is often sweet to me.
Not to me.
Not part of the reason.
The reason.
The reason for the Lord and Saviour for us and
God is not, etc..
All our sins are negative.
This song called him at all is called the Master.
He said, are saying you are ready for the mega
mega mega mega mega mega mega mega most of our
Lord Jesus.
Amen.
It is he are to be there also are remarkable
for said both my Lord and said both my own
and money of the dominion of my Lord.
And but in your body, your money, your body, your
friends, they call me Norman, said to are your body,
your body, your body all say.
But when the morning that he of your the body
of the body, your body of all, and be ordained
for.
But as an ordinary day, your body is an ordinary
An Eagle Ford astronaut and.
Former astronaut.
Okay.
If you were listening carefully, you might have noticed that
it started with this.
And then there was a second verse, which was slightly
different.
There are several versions of this rhyme, so I think
he set two of them, but I'm not quite sure
because I can't find the score for this online and
I'm too lazy to do it elsewhere.
, if you want to look this stuff up, these
are the sources I used.
, that is Aristotle in translation.
Stanford Encyclopaedia of Philosophy.
If I haven't mentioned this, I should, because it's an
invaluable resource for all kinds of philosophical logic and all
other kinds of logic as well, despite being an encyclopaedia
of philosophy.
, and in particular, this article will tell you about
Aristotle's logic in a reasonably accessible way.
Sharp articles are written at quite a high level, but
they are generally understandable.
This is a link to some stuff about the medieval
theory, and this was a handy blog that I found
by somebody else who's a medievalist, medieval logician, or what
have you call it.
Who unpacked all this stuff?
Because this is on Wikipedia, but the Wikipedia entry is
seriously crap, and I haven't taken the effort to improve
it myself.
Okay, so that is the end of part one.
I don't suppose there were any questions, but if there
are any questions I can take.
These any of the words in the right hand?
Oh, yes.
, some of the words mean something.
So Keller and they are hurrying.
, clients, those who are hurrying diabetes.
You will give faster no I hurry says
I vocative of no ablative of Caesar.
.
Yeah.
So there are some random stuff.
There is.
, well, as far as I know.
So the words ending in on look Greek, but
I don't know whether Burgh lepton is a Greek word
or not.
, not obviously.
Phil Upton, I'm sure is not Decimus, I think means
something in Latin, but I can't remember because it's a
long time since I did Latin.
So yeah.
Thank you.
So I think they chose a word that existed if
they could think of one at the time.
Okay, so what's part two?
I promise to say a bit more about regular expressions
that we were talking about last week.
So.
That is not working properly.
Is it because.
It's a non-standard slide.
Because I don't want you seeing the next slide.
I just want you seeing the current slide.
, this is another talk I gave to my institute
after I started teaching this course, because in the course
of teaching this course, I learn more about regular expressions
than I had previously known.
And I thought this stuff would be fun for them.
And then what about you?
So this is regular expressions as we teach it to
you, and you will do more of them next year.
So if you remember I talked about the computer science
notation versus the programming notation.
So we have the input symbols single letters, empty string,
concatenation, union, which we might write with the set union
symbol.
And we have the star that's the looping operator.
E star means any number of repetitions of whatever E
does, and we use brackets all over the place in
the usual way.
I don't think I even said that because it's just
obvious.
And we can't do intersection and complementation and negation with
regular expressions, because we can't do them with nondeterministic automata
nicely.
If we want to do complement and intersection with nondeterministic
automata, we have to turn them into deterministic ones, which
blows them up.
So if you remember.
So this is theory I mentioned programming notation.
So where did the programming notation come from.
Well in real life that meant mostly Unix.
And for a long time there were two programs grep
and then later e grep , which are what you
use to search for things in a file.
And the Unix notation is letters concatenation union written with
a bar, the star parentheses.
And then all this sugar that I mentioned last week.
So syntactic sugar remember is stuff that makes it easier
to write but doesn't give you any new power.
Anything that is an A, B or a C something
that is not A to Z.
It's something that can make sense in a word, an
optional x, y, z at least one a.
And I didn't mention this, but one of the things
that is often available is between 3 and 7 copies
of BCC.
Not something you use very often, but you use it
sometimes.
.
I also mentioned right at the end of last time
in a bit of a hurry, that in normal use
of regular expressions, you write one and it matches anywhere
in the string.
But we often want to anchor it as it's called
to the beginning or the end of the string, which
is what we did when we were doing them with
automata.
So this is the expression that matches the entire string
in the comma omega.
And in everyday life, it's useful to have things that
match at the beginning or end of a word, for
example.
So this is a string that matches the word v,
because the backslash b is a special symbol that matches
the empty string, provided it becomes between a letter and
a non letter.
So match is the edge of the word.
And there are lots more of these things.
And actually there are more of them than I can
remember.
And this stuff is still syntactic sugar, but I reckon
you might have to think a little bit about how
you will write down the automaton to do them.
, particularly with the zero width things, you can do
it.
, then things changed.
So Larry Wall, the great Larry Wall invented the programming
language Perl, which I may just have mentioned a few
times.
And Larry was Larry invented Perl for a very, very
practical reason.
It was his job to produce a large number of
reports about data.
And so he invented Perl as a language to make
it very easy to produce reports about data.
So Perl may possibly stand for practical extraction and report
language.
, or alternatively, it stands for pathologically eclectic.
Rubbish.
Lister.
Mm.
.
You had a talk from Phil on Monday, right?
Phil is one of the leaders of the programming language
group.
He probably thinks he's the leader of the programming language
group.
But other people might have different ideas.
And whatever they do, Perl is the opposite of.
So every principle of good language design, Perl does the
opposite.
So I've told you, most of my programming is in
Perl.
And the general idea of Perl is if you see
something that looks cool in some other language, steal it.
Very much in the way that.
So the same approach that English takes to other languages,
Perl takes to programming languages.
That, by the way, is why my poor tutorial group
are mostly here because I've moved their tutorial to after
this lecture here.
, so lots of things which you will learn about
at various points associative arrays.
If you've done PHP programming, you know about those references
we haven't told you about.
Call by name.
You may learn about at some point dynamic binding, static
binding.
If you do advanced language classes or whatever there is,
Perl probably has it and it never gets rid of
anything.
So Perl is very backwards compatible for 40 years or
so.
Not entirely, but as much as you can be.
Oh, and if there's stuff in other languages that people
think is good but it gets in your way, then
forget about it.
So we've been telling you why types are a good
thing.
Perl's attitude types is, well, it might be convenient to
have strings and numbers, but it's also convenient if I
automatically convert between them whenever I think it would make
sense to you, which is almost all the time.
Very useful.
So Perl wasn't the only language that was pushing for
more complicated regular expressions, but it's the most influential.
I say probably actually, it just is, because nowadays we
have things called Pcrs.
I mentioned them last week.
Perl compatible regular expressions or preposterously convoluted regular expressions.
That's a Larry ism, of course.
And those things have spread some ghastly disease, and
they found their way back into even the original Unix
utilities.
So once upon a time, grep was a nice, simple
program which just searched for a regular expression in a
file.
Nowadays, you can choose what sort of regular expression you
want, and if you want to use Perl regular expressions,
you can with some reservations because as we'll see, regular
expressions are so complicated that it's not always obvious how
to implement them.
So what can you do?
This is something I mentioned again quite late in the
last lecture.
When we actually use regular expressions in real life, we're
not just saying does it match, we want to know
which bit of the input matched.
And in real life we have cleaning star and alternation.
So that's supposed to be non-deterministic but we can't do
non-determinism.
So as I said we have deterministic nondeterminism.
So here's an example.
In normal regular expression syntax this means look for an
angle bracket followed by any number of anything followed by
an angle bracket.
So dot means any character and star means any number
of.
So you might hope that this would find XML HTML
tags.
And if you don't know what XML tags are, they
are HTML, but more general.
And so in particular, they are extremely annoying to deal
with.
Does this find the tag irritating when I match it
against this input?
Yes.
Anybody think otherwise?
Actually, by default it finds the bit between irritating and
that irritating.
Because the general approach to star is this says any
number of anything.
Well, we could say that means that number.
Or we could say it means that number.
It's non-determinism.
So if this were actually a non-deterministic finite automaton, both
these paths would be accepting paths.
We can't do that.
What do we do?
in real life.
Regular expressions.
We implement this in what is called the greedy way.
When you're trying to match this, you swallow up as
many characters as you can with the star, and then
you see if you can find the angle bracket.
So if you take the greedy approach, you read the
angle left bracket, then you read dot and you keep
going.
So actually you keep going all the way to the
end and then you say, whoops, I can't find an
angle bracket.
So I go back one back one back one, back
one until I hit there.
And now I've read as many dots as I possibly
can and then find an angle bracket.
, often this is not actually what you want.
For example, if I wanted to pull out the tag
irritating from here, what I want is the opposite of
greedy.
I want the thing that swallows up as few things
as possible.
And in traditional Unix regular expressions, you had to work
around it by doing things this.
Let me look for an angle bracket followed by three
things that are not an angle bracket as often as
possible, and then an angle bracket.
And this gets very boring very soon.
So in modern Perl compatible regular expressions, we can write
star query to mean swallow up as few things as
possible, and then find an angle bracket so that finds
the tag irritating in the sequel.
, is it obvious that doing this isn't giving you
any more expressive power?
It's maybe not totally obvious.
This particular one doesn't, because you can always work around
it by doing something this.
But that's not the only way.
Why do I say this is calling backtracking behaviour?
Because what this is saying is we want to do
as little backtracking as possible.
So always look to see if you can find the
angle bracket, and if you can then stop swallowing up
with the star.
Whereas the standard implementation says swallow off as much as
possible and then back off until you can find an
angle bracket.
, another thing, and actually this is something we do
use, I was looking.
So the university email system is extremely annoying, right?
Do you find it extremely annoying or are you just
brought up with outlook?
So you're used to this crap and therefore don't understand
why it's crap?
It does many very annoying things.
In particular, it corrupts your email by inserting stupid messages
at the beginning.
you don't often get mail from so-and-so.
And so I have a filter that filters out all
this rubbish, and one of the filters actually uses this
stuff.
, when you write a string in a programming language
Haskell or JavaScript or whatever, you have the problem,
that you write it inside quotes.
And what do you do if you want to have
a quote in the string?
There are two standard approaches.
One of them is to say.
I will use a magic escape character.
It's called an escape character because it somehow escapes from
the special meaning.
Says this quote is not the end of the string,
it's actually the actual character.
Some languages do this.
By doubling the character you want, but this is the
most common one in languages today.
, now JavaScript is a language which allows you to
quote strings with either single quotes or double quotes as
long as you match them, which is actually quite useful
because in JavaScript is used for writing web applications and
in web applications, you are putting a lot of text,
and you often want to put quotes or double quotes
in the text.
PHP does the same if you are doing web programming.
So if we ignore the matter of escapes, then this
is a match for a JavaScript string.
And what it says is the string begins with either
a double quote or a single quote, and I'm putting
brackets around it to tag that as a single thing
that I can talk about later.
Then it has anything, any number of times, and we
want it to be greedy because we don't want to
see any, quote, symbols.
And then it has the same kind of quote we
saw at the beginning.
So in particular.
That's a good string because I see a double quote
and then I swallow anything.
I swallow anything, as few of anything as possible until
I see another.
Whatever I saw first and equally.
That's a good string.
Recognise that expression.
So that's quite useful.
, and in this particular case, it's fairly obvious that
you could do it with old fashioned regular expressions too.
However, you can also write down something this.
This says I read some number of A's and then
I read a B, and then I read the same
number of A's as I read before the B.
This is not something that can be done with finite
automata.
So you will prove this in inf two.
But you might to think about why you can't
do it with finite automata.
And even worse, this is a thing that says I
read a string and then I read the same string
again.
, that's also not something that can be done with
finite automata, and it can't even be done with some
more powerful notion of automaton that you will meet next
year.
, let's skip that because you don't know about it.
So you might ask if you add this stuff.
What is the power of the expressions you get?
It's certainly more than finite automata.
And it's more than these are called pushdown automata, these
things that let you do more.
But what is it?
And actually, I don't know.
And I can't find anybody who's gone to the trouble
of tying it down.
Precisely.
, this is common.
So lots of languages allow you to use back references.
, that's only the beginning of the stuff Perl does.
So it also does things let me look ahead
without actually doing a match.
So this says I want to read a string of
digits.
So backslash D is a digit at least one of
them.
And when I get to the end look ahead to
check that it's followed by a word but don't actually
include the word in the match.
So this is sort of peering ahead but not actually
eating the word.
, this is something that I wrote down in an
attempt to match a standard floating point number, and later
realised that I got it wrong.
So I'll put the slides on back on the page
after tomorrow's lecture.
So if you want to do the exercises, you can
, and this kind of thing is quite powerful because
it means you can do intersections.
So if I say at the beginning of the string,
look ahead to see if it matches pattern one and
then swallow pattern two, that means that the string matches
pattern one.
Intersection pattern two.
So suddenly we've got intersection of regexp and therefore intersection
of finite automata.
And I think that this doesn't have any power, but
I'm not entirely sure.
, I think I won't talk about backtracking control because
it's a bit complex.
, then we get recursive regular expressions.
So one of the most annoying things about regular expressions
is that you can't use them to match brackets, and
matching brackets is what you want to do in every
programming language you ever write or ever analyse, and also
in your English if you want to write, well, decent
English.
, so Perl will let you write a regular expression
to match a balanced parenthesis.
So what it says is, well, the parenthesis starts with
something that is a bracket followed by An arbitrary number
of things that aren't brackets, either open or close, and
it ends with a closing bracket preceded by an arbitrary
number of things that aren't open or closed brackets.
And in the middle it's got the same regular expression
again.
So this is a recursive call of the same regular
expression, which is quite cool.
, this is a famous example of a non regular
string.
This can't be matched with finite automata.
You will prove that next year as well.
But this very simple recursive regular expression matches it.
, that's pretty bad.
Very useful, but pretty bad.
But because Perl is Perl, it actually lets you write
an arbitrary program inside the regular expression, which can look
at what has been matched so far and do stuff
with it.
, I have never seen this in practice because I
don't think I can't imagine why you would want to
do this.
, it does have a manual.
Perl has a very good manual for its regular expressions.
Here's a couple of key extracts.
, yeah.
Okay.
Now let's get back to good old fashioned regular expressions.
Have you ever come across a website that has failed
to validate an email address?
If you have nice, simple email addresses, you won't have
this problem.
But if you have any slightly sophisticated email address, an
email addresses can be a lot more complex than you
think they can.
And how do people validate them?
They match them against some regular expression, which they dreamed
up because they thought they were clever.
, if you actually want to validate email addresses according
to the email standard, the right regular expression looks
this.
, it goes on a good bit further down the
page, and that doesn't even address the fact that you
can put comments in regular expressions.
Okay, so that was regular expressions in everyday life.
And that's today.
So tomorrow is infinity big numbers and some pretty pictures.
So hopefully see most of you tomorrow.
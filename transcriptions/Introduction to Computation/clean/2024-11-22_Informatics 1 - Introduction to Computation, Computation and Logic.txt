Well, it's good afternoon.
Your reps have asked me to make an announcement.
I imagine that you.
Well, I don't know.
You should be the people who the announcement is directed
to, but I just thought you don't need it anyway.
Apparently some of you are having difficulty finding places to
work when you're stuck hanging around here between activities, and
the reps asked me to point out that this building
is the most crowded building.
There are many other buildings on this campus, and GMB
apparently has screens showing you where working areas are, and
the upper floors of GMB are often relatively empty.
GMB is a very interesting place.
I spent 20 years there and there are still bits
of it that I haven't been to, so you can
go and work in there and find all the little
corners that nobody else will ever find.
Just make sure you take a ball of string to
get out again.
Are there any questions from yesterday?
There was a lot of concept and notation yesterday.
You're all gone through it.
Or shall I just continue straight on assuming everything is
fine?
Now what if we'll just go straight on?
So let me remind you what we did yesterday.
We introduced a slightly weird notion of non-deterministic automaton, which
we can basically think of as an automaton, where we're
exploring lots of possibilities simultaneously, and all we require is
that one of them works.
One of them turns up with the good answer.
And I told you, the reason we would do doing
that is because they're easier to work with in practice.
But I haven't yet given you a convincing explanation of
why we want to work with them in practice.
So that's where I'm hoping to get to today.
But before we do that, I'm going to introduce yet
another refinement, yet another extension.
It's another slightly unnatural thing, but also very useful for
reasons that will become obvious.
I'm going to define something called an epsilon NFA.
By now you should all have learnt your Greek alphabet,
so you should know epsilon.
And this is a notion of automaton which has a
special symbol, epsilon, which is not part of the input
alphabet, but we can write epsilon transitions.
So I can write an epsilon transition between two states.
And what does that mean?
Well, it means that the machine can, just of its
own accord, decide to move between these two states without
actually reading any input.
Now, I just said decide.
Of course it doesn't decide anything.
This is just non-deterministic.
So at any point in the execution of the machine,
you have the possibility of moving along an epsilon arrow
or staying where you are.
And as with the previous explanation yesterday, all possibilities are
explored.
So.
If I draw this machine and it reads an A.
There are a couple of things that might happen.
It might read an A and end up here or
before reading the A might run.
It might just go to this state and then read
the A and end up there.
So remember, things are good if any of the possibility
ends up in a good state.
So that particular epsilon automaton accepts the single input a
why do we do this?
It's a technical tool.
It makes life much easier to build machines that recognise
the concatenation of two strings, or that recognise the repetition
of strings, and that is something we do a lot
in practice.
So I will show you this fairly shortly.
Have I made it more difficult?
.
Not really.
Everything we've done so far goes through.
If you just pay a little bit of attention to
the details.
, goes through a very dangerous mathematical phrase.
Mathematicians will say, oh, yes.
I make the slight adjustment to the definition.
Everything goes through.
, what they mean is somebody, hopefully them, has done
the work of checking that everything still works.
In particular, the subset construction that we did yesterday where
we built a deterministic machine by taking the states of
the deterministic machine to be the sets of states of
the nondeterministic machine still works.
So we haven't really added any power.
We just added a gimmick that is useful in practice.
And we can still determine I's an automaton and we
still recognise regular languages.
So what do I mean by everything goes through?
Well, we can still build a product of two automata.
There's a little bit of work to be done with
the epsilon transition.
You can find the details in the book.
.
So product works just Dfas.
And whether you have epsilons or not is just a
small detail.
What was the other thing that we did with the
deterministic automata?
We said it was easy to complement them.
We can recognise the strings that are not in a
language.
This is the big thing that we have lost by
adding nondeterminism.
So why have we lost it?
Yesterday I asked you could we have decided made any
different choice than saying we accept if any one ends
up in a good state?
One of the alternatives was any was all ones end
up in a good state.
That's obviously not the same thing.
Why can't we complement a nondeterministic automaton?
Well, exactly.
Because we say that an NFA accepts if any of
the executions is good.
So if we complemented it, we can't just flip the
accepting states, because we would also need to say, look,
all the executions end up in the new accepting states.
That is the old bad states.
And that's not how non-deterministic automata work, because they require
any execution to succeed.
, what this says is not exists is the same
as for all, which by now you all should know.
So we can't make an easy, obvious compliment construction on
a non-deterministic automaton.
How could we build an automaton that recognises the complement
of a nondeterministic automata.
Automatons.
Language.
Anybody?
Well, what can we do?
We know we can convert it to a DFA, right?
Yesterday we did a conversion to a DFA.
, and we know that we can write the complement
of a DFA.
So in the worst case, if we can't think of
anything clever to do, we can always turn the NFA
into a DFA, do the complement from last week, and
then we have the result.
So the problem with that is that when you do
the determination process that we did yesterday.
You're dealing with sets of states, so the size of
the automaton typically blows up exponentially.
And generally speaking, we to think of negation as
a nice, simple operation.
We don't expect it to lead to an exponential blow
up.
However, it's a fact of life.
Well, it's a fact of mathematics that when you introduce
this kind of non-deterministic idea, then complementation gets complicated.
Exactly.
Because Nondeterminism says there exists a path that works.
And so if we negate it, we have to say
for all paths that work, and then we have to
look at all of them.
, yeah.
So questions about that.
And you might wonder how often do we actually want
to do complementation in practice, not all that often, but
occasionally it's useful.
But usually when we want to do complement, we want
to complement something very small.
We want to say things , , I want to
see a word that does not begin with a.
And that's an easy thing to complement.
What else can we do with Nsfas?
Well, we can build the sum we saw how to
build the sum.
We just put them side by side and take the
union of the states.
So we did that yesterday.
We don't need to do anything fancy.
We don't need to build a product.
We just take the two amata two automata, draw them
on the same piece of paper and say the union
works.
, lots of notations.
Some people write that the thing that the epsilon automata
have brought us is that we can build things that
recognise the concatenation of two languages.
And what do I mean by the concatenation of two
languages?
If L is one language and L is another, then
the concatenation is simply things that have a string in
the first language, followed by a string in the second
language.
And that's something that we use a great deal in
the applications of this stuff.
Because if you're recognising Haskell syntax or any other language,
then you are doing a lot of saying a sentence
is a noun phrase followed by a verb phrase, and
a noun phrase is a determiner followed by some adjectives,
followed by a noun or whatever.
Or the equivalent in programming languages.
So concatenation is the one the single most used operation
when we're actually doing language processing.
So it would be nice if it were very easy
to do it.
You should take a little time to think how you
do it deterministically.
It's not hard, but it's just needs a little bit
of attention to the way you plug the two machines
together.
When we go non-deterministic, then it's not quite so obvious
how to do it.
If you think about a non-deterministic automaton and how to
plug it together.
Then you will find that the details get a bit
fiddly.
But if we have these epsilon transitions, we can make
it very, very straightforward.
So there's a formal definition.
So here I've got my two epsilon non-deterministic finite automata.
And they have different sets of states.
So I stick the states together.
The transitions are the unions the final states.
Well what are the final states.
And then I add some extra transitions.
So these are the transitions in one.
These are the transitions in the other.
And then I'm adding more transitions.
These are all epsilons I'll give you a picture in
a moment because the picture is much clearer.
And the epsilons are just joining the accepting states of
automaton one to the initial states of automaton two.
That should make sense, because what is.
If you want to see strings in this language, followed
by strings in this language, you run the string on
automaton one.
It accepts.
Then you start this.
The rest of the string on automaton two.
If that accepts, you've got a concatenation of the two
strings.
But when things are non-deterministic, it sounds a little bit
more complicated, because what if you end up in the
wrong kind of state?
So let me put this in words.
Put the two machines side by side.
For example this one and this one.
So what does this one do?
This reads.
This accepts strings that begin with two A's or begin
with two B's.
And this one is the one that accepts a string
that ends with a b.
So hopefully if we stick these two machines together, we
want to get something that accepts strings that start with
two A's or two B's, and that afterwards end with
an A and a B.
To do that, I want to join the accepting states
to the initial states.
But I want to avoid confusing matters by making this
state accepting.
So you might think, can't I just glue these two
states together into one?
But then I will get confused about what's accepting and
what's not.
So what I can do is to just draw some
arrows from the good states here into the initial state
here.
So in this one, which doesn't have any epsilons to
start with.
It could have, but it doesn't at the moment.
I read my string.
And in the States where I have successfully read a
string from the first one, I can jump to the
start of the second one and start looking for string
for the rest of the string, ending with AB.
And that's nice and easy.
So the notation is a bit fiddly, but the picture
is easy.
Okay.
, as I said, go away and think about what
you would do if you didn't have epsilon transitions.
How would you glue these together and make sure that
it worked precisely?
And the thing that really gets much easier is something
that we also want to do a lot, which is
to recognise lots of copies of a string.
So a typical piece of discourse or piece of text
has many copies of whatever your thing is.
Lots of sentences.
Programming language is a lot of repetitions of the same
construct.
So if you remember a little while back, I introduced
the star notation.
Star is arbitrary repetition of something.
That's something that we want to recognise a lot.
So here's the machine that recognises A, B or BA.
Here's the machine that recognises strings that are made up
of sequences of a, b.
So you can you see a ba a b a
a any number of repetitions of either of these two
things.
And this is quite neat because I haven't had to
do anything except jump from the final states to the
initial state.
And again, you can go away and try to do
this with deterministic automata or non-deterministic or better non-deterministic automata
without epsilons.
And you'll find it's hard at work.
Of course it's not impossible.
It's just Fiddler to write down correctly.
Right.
So that's a couple of several things I've introduced complement
product some concatenation and looping.
So I should pause and say do you want me
to say more about any of these?
Yeah.
Say that the section of the empty set.
Why is that.
So if for some I say what?
Oh, here.
, that's just a technical detail.
I'm saying that these are two distinct automata.
If that weren't true, then I would be talking about
two automata that have a state in common.
So it's purely a notational fiddle.
Mathematical precision.
We never think about taking two automata that happened share
a state, because that's what we're building.
, so if you're if you're a mathematician, then you
might write it differently.
You could write disjoint union or something.
So I could write.
Yeah, I could write disjoint union there if you're happier.
In fact maybe I should, but I'm never sure whether
everybody actually knows what I mean.
If I write down the disjoint union sign.
Okay.
Any other questions about the sum.
Or the concatenation.
So that's I think intuitively very easy to do.
Can't get much easier than just sticking the final states
to the accepting states and looping is even easier.
Okay.
Do we write down automata in practice when we actually
want to recognise languages?
No, of course we don't.
So how do we actually write down regular languages when
we are writing something to parse a program?
So if you're trying to recognise a piece of Haskell,
what do you do when you write the program that
analyses a sequence of characters and says, This is Haskell?
Well, actually it gets quite complicated.
And if you will do courses on this in third
year compiling techniques, , a bit of advanced warning.
Compiling techniques has always been one of the hardest courses
for most people.
I hated it, but I had to do it because
there's lots of technical stuff and it all looks
this, but harder.
, what you want to do is to be able
to write a nice, simple textual notation that describes the
language you're trying to recognise and have some tool, some
program, do the work of turning it into automata and
running them for you.
So this is where we introduce something that is actually
useful in practice.
So I use these every day pretty much.
Is that true?
Well, almost every day.
There are things that we call regular expressions.
, there is a dispute about what the right abbreviation
for regular expression is.
Some people will say regex, which has the advantage of
being a pronounceable English word.
Some people will say regexp, which has the disadvantage of
not being a proper English word.
And what they are is a simple, simple programming language
with a very simple textual programming language.
And I think I asked you last week whether you'd
seen them and a few people have.
I suggested that you go out and find about using
them because they will make your life much easier, particularly
when you're writing programs and you want to change something.
So you've all used find and replace in your word
processor or your text editor, right?
I mean, I imagine everybody has used find and replace.
, find and replace can be very simple minded.
So it might just say I want to replace every
occurrence of the word foo by the word bar.
But when you have regular expressions and a powerful editor,
then you can do much more complicated things and replace
lots of words at once with a constant part and
a varying part by saying something .
Oh, I shouldn't wife over there because it's not visible
online.
, don't mean that.
Actually, I didn't mean to do that.
Forget that.
So this is a simple thing.
Suppose for some reason known best myself.
Have the audio gone or not?
.
Suppose for some reason known best myself, I've all named
all my variables starting foo, and my boss comes along
and says that's not the standard.
This project names all variables starting bar.
What do I do?
Well, I don't want to go through doing a search
and replace on every variable.
But what I can do is say look for every
word that has the form foo followed by some letters
and replace it by.
That should now be one.
And replace it by bar, followed by the sequence that
I found.
So that's the kind of thing that one does in
editors.
A lot.
And I'll explain a little bit about the syntax of
these things.
, of course, sometimes it's easier just to do the
thing by hand anyway, but it's generally more fun to
try to work out how to do it with a
regular expression search.
, now, this is supposed to be partly a theory
course, and it's an unfortunate fact that there's a traditional
way of teaching regular expressions in theory courses using one
notation.
And that notation is not the notation that everybody uses
in actual practice in programming languages and editors and everything
else.
So I thought I might as well just use the
programming language editor notation, because that's what you're going to
use whenever you actually use a regular expression.
So be aware that if you go and look at
books, you will find an alternative notation.
What's the main difference?
When we're doing theory, people tend to write union, whereas
in programming languages people tend to write a vertical bar
symbol for all.
, and in programming languages, we have lots of stuff
that makes it shorter and easier to write things.
Have you heard the phrase syntactic sugar before?
Nope.
One or a few people.
So syntactic sugar is useful.
What does it mean?
So it's sweet because it makes everything sweeter and easier
to do.
And it's also unnecessary sugar.
So syntactic sugar is bits of syntax that make things
shorter and easier to write, but which you don't, strictly
speaking, need.
And most programming languages have quite a lot.
So when you study programming languages that more or less
any level, you will find out that you don't need
for loops, you don't need for loops, because you can
always turn a for loop into a while loop and
vice versa.
So why do we have for loops and while loops?
It's because it's easier sometimes to think about while and
easier to think about for and languages who are designed
for.
People with extreme laziness have more sugar.
So I mentioned my favourite programming language, Perl.
It's notable for many things, and it has vast amounts
of syntactic sugar and lots of slightly different constructs which
can confuse you.
, so here's the programming language definition of what a
regular expression is.
I'm going to define it in a vaguely mathematical way.
So I'm saying I've got an alphabet.
This is the input alphabet of your automata.
And I'm going to define the class of regular expressions
in a mathematical way, which is basically the same as
defining them in Haskell by a big recursion.
And each time I define a new type of regular
expression, I will define the language accepted by them.
So my base case is.
If a is one of my input symbols, then a
by itself is a regular expression.
And what's the language?
It accepts a okay.
Epsilon is a regular expression.
It's a very special regular expression.
It accepts the empty string.
No input at all.
Okay.
And the language it accepts is only the empty string.
Then I'm going to define ways of sticking to regular
expressions together.
And this does exactly what you expect it to do.
If I've got two regular expressions, r and s and
I write r s, then what I expect to happen
is that it's the strings that have something in R
followed by something in S, it's the concatenation.
So if r and s or regex is, then r
s is a regex and the language it accepts is
the concatenation of the two languages as defined earlier.
Remember, this means exactly anything that is a string in
L of are followed by a string in L of
S.
If I've got two regular expressions, then I can form
the sum or the union.
So this is exactly the same as the automaton.
Some construction.
As I said, most all programming languages I can think
of right now, although there must be exceptions, right?
A vertical bar for the all symbol.
And the way you remember that is that it's just
the logical or so we're saying.
We're looking for a string that is recognised either by
R or by S.
, finally there's the star.
So this is the cleaning star that I introduced and
this is the looping operator.
What do I mean by that?
I mean it recognises any string that is any number
of repetitions including zero of a string recognised by R.
So strings in the language of are repeated any number
of times, different string each time, of course.
And the zero repetition means that the star operator always
includes the empty string, because the zero repetition is just
the empty string.
.
That's the kind of formal definition, but it's.
Relatively obvious.
Okay.
So that's really just notational definition relating it to automaton.
Any questions about the notation.
A couple of examples.
So the language from a couple of slides ago where
I was looking for strings that were a sequence of
a, B or BA.
So that was the automaton where I had a b
ba.
And then I looked back in regular expression terms.
That's just this thing either a, B or bei or
ba and I looped them.
So the star operator is essentially looping.
This is the one that demonstrated the concatenation of two
languages as well as some looping.
So this is the one where strings have to start
with either A or B.
After that, they can do anything as long as they
end with a b.
And this kind of expression is about the level of
complexity that you will typically be working in practice.
This one is extremely hard to work out, so I
have to admit that I did not work this out
by myself.
I tried for a while and then I gave up
and googled it.
, it is possible to.
We know that we can write down a deterministic finite
automaton for the language with an even number of zeros.
We did that early last week, and therefore there must
be a regular expression describing it, but it turns out
not to be at all simple.
So you might to go away and think about
Why it is that this regular expression is so much
more complicated than the very simple DFA that we were
able to write last week.
And to think about that, go and look at the
DFA and then think about trying to turn it into
a regular expression, just by using your native wit and
following your nose and seeing where you end up.
.
So this is not the kind of thing that you
typically write down in a programming language.
If you need, if when you're writing a parser, you
actually need to look at strings with an even number
of zeros in it.
You'll probably have a separate function to count it, because
that's less work than actually writing this regular expression.
.
So regular regular expressions are syntax.
What can they do?
Well, regular expressions are constructed by reference to automata.
So the constructions I gave you for regular expressions were
concatenation.
Some.
Looping.
Was that it?
That was it.
So these are the same operations that we had for
non-deterministic finite automata.
And therefore it's completely straightforward to take a regular expression
and draw its automaton as long as you're drawing a
non-deterministic automaton.
And I claim that it's so easy that it wasn't
even worth my while spelling it out in detail because
you just match plus to, plus sorry bar to plus
concatenation to concatenation, and star to loop.
If you really need to see it spelt out in
detail, then the details are in the book because the
book has all the details.
What does that let us conclude?
Well, we know now that if we have a regular
expression, it's language, the language that is recognised by the
regular expression.
Is the language recognised by a nondeterministic finite automaton.
And that means it's a regular language.
So it's also the language recognised by a deterministic automaton.
So if we wanted we could determine size it and
blah blah blah.
So everything is the same regular expressions dfas nfus.
They all recognise the same classes of language, which is
a reason why the regular languages are a very nice
class, a nice and simple class.
, so you can think about one thing you might
want to think about.
This is just a little exercise to do afterwards.
Take this regular expression a b.
So view this as a regular expression and apply the
constructions to it and see what you come up with.
And then just write down the automaton that you would
naturally write and think about why they're different.
, actually, I'm going to do it for you, so
I'm going to hastily skip over it and let you
think about it.
Don't look at the slide.
, it shouldn't be surprising to you that this was
a two way thing.
So a regular expression describes a language that is regular.
If I take any regular language, I can build a
regular expression to describe it.
You might think that this should be easy as well.
Unfortunately, it isn't easy.
It requires work, and there are two ways to do
it.
The book describes, first of all, the way that I
think is harder to understand.
Therefore, I'm going to give you the other way because
I think it's much easier to understand, and it's also
easier to do in practice.
So the way in the book basically proceeds by solving
equations in regular expressions, which is another level of conceptual
burden that I don't think we need.
Whereas there is a way where you can do it
just by mashing things together until you get the answer.
So my problem is, given an automaton, how do I
compute the regular expression that accepts exactly the same language?
And essentially the idea is to introduce a more complicated
notion of transition and start smashing states together and instead
writing more complicated transition labels.
So the fundamental example of doing this.
Here's an automaton that accepts a b.
So this is the one I would naturally write down
to represent a b.
And I want to turn this into a regular expression.
Well I look at this state.
I observe that I could just delete it and say
that I can write an arrow that is labelled by
a b, because if I see a B, I have
to go through this state.
So I might just as well say there's a single
arrow which reads A and B it in sequence all
at once.
Where does life get complicated?
Well, life gets a little bit complicated if there are
loops, but not very hard.
So self loops are often tricky.
We've written this construction often this is strings that start
with an A and end with a B with anything
in between.
Well, self loops turn out to be very easy to
describe because they just look this.
I look at the symbols on this arrow that's A
and B, and then I say I can just do
those any number of times.
, so far so good.
Notice that I've used several constructions.
So I've used concatenation to concatenate.
And I've used or here to combine a multiple transitions.
Remember this is really a shortcut for two arrows one
labelled A and one labelled B.
And I've combined them together with or.
And then I've used the looping construct because this is
a loop that I can go around any number of
times, including none at all.
, but it's maybe a bit harder to see.
What do we do if there are loops here in
the initial state?
What do we do if they were loops in the
final state?
, that's a slightly harder problem to deal with.
If you try to do the obvious thing, you'll find
it doesn't work.
So what we do is use epsilon transitions.
Here's an automaton which has some initial states and some
final states.
It would be easier if there were just one initial
state, which there is, and just one final state which
there isn't.
With Epsilon, we can take any automaton and make a
special initial state that is distinct from the original automaton,
and a special final state that is distinct from the
original automaton, so that we only have one beginning and
one end to worry about.
So all I'm doing here is saying I'm adding a
new dummy state, which then leads to the original real
initial state, and I'm adding a new dummy final state,
which all the original final states lead to.
Once you've done this, then these things can be concatenated
very straightforwardly just by gluing together this state with that
state.
So now we repeat.
So in this one I would start by I would
remove that state and replace it by an ab arrow.
I would remove that state and replace it by a
bar arrow.
Then I would union these two transitions to get a
BA or a B and so on.
It's straightforward and it's easy to program and it's quite
we don't ask you to program it I don't think,
but it's quite a good exercise.
What we end up with when we do this is
one arrow from the dummy initial to the dummy end
with an enormous regular expression on it, which is the
one we want, which describes all the strings accepted.
So that procedure, I think, is quite easy to understand
and do.
And that means that we have proved that the regular
expressions describe exactly the regular language.
Every regular language has a regular expression, and every regular
expression describes a regular language.
, as I said, the book describes the other technique,
which is the one that I was taught when I
did this kind, of course, as a student.
, it might be easier to program, but I found
it much harder to understand intuitively.
Do go away.
Have a look at it.
You might think differently from me.
And as I say, if you're feeling relatively strong, you
have enough coffee inside.
You try doing this technique on the even odds and
even one machine, and see whether you end up with
that regular expression or not.
Okay, so that's quite a lot of new notation.
Again, this has been a very heavy week for notation,
which maybe not the ideal way to end the core
content of a course, but hey, we have to teach
it.
Any questions on this stuff.
We do, of course, have next week for you to
ask questions if you need it.
, I want to finish off this topic by saying
a little bit about a little bit more about regular
expressions in real life.
I said they had syntactic sugar.
I haven't introduced much syntactic sugar.
So for your practical education, rather than your theory education,
let me mention a few of the things that you
will see in most actual implementations of regular expressions.
So these are things that pretty much every implementation has
in fact.
, though is pretty much a standard implementation of regular
expressions.
Well, there are two standards because you can never have
enough standards, right?
So anybody heard of Posix?
No.
Okay.
So Posix is an international standard for Unix operating
systems and most operating systems.
So it's the operating system and the whole programming environment.
And it was designed for Unix.
But these days almost everything else has a Posix compatible
mode, even windows.
And one of the things that Posix does, Posix does
is define regular expressions in what was the traditional Unix
way.
.
However, I mentioned my favourite programming language, Perl, many times,
and one of the really striking features of Perl is
that it has regular expressions on steroids.
Not so much on steroids as on every illegal drug
you can think of, and then some that you haven't
thought of because they're very, very useful.
And actually, Perl's regular expressions are not regular expressions.
They're much more powerful.
And that's something I have a talk about, which I
probably won't have time to do next week, but you
never know.
, and people them so much that almost all
regular expression libraries, including the ones used in your browsers
and so on, now have a mode where they support
P-series Perl compatible regular expressions.
These are not PCR.
These are quite old fashioned ones.
Well, these are also pieces.
So one of the very common ones is something we
want to do a lot is to say I want
to look at words starting with a vowel, starting with
a consonant, or starting with some other bunch of characters.
And it would be a real pain to write down
A or B, or C.
Well, I can just write down a, b, c in
square brackets.
So the square bracket notation is used a lot.
It's a real pain to write down a, b, c,
d, e, f when you can just write down a
to F, so that we use a lot in programming
language syntax analysis.
This is an example of a simple regular expression, which
we want to complement a lot because we often want
to talk about.
I want my piece of syntax to contain any character
except something.
, how many of you have been annoyed by inventing
a password for some site and it telling you it
is not a valid password without explaining why it's not
valid?
Now, if only they would tell you the regular expression
you had to match.
You could do it because there is a regular expression
in there somewhere, which is it is matching against.
So negated character classes are very common.
Optionality is useful.
So we often want to say I want a word
optionally followed by some other word.
We can write that as the empty string or the
word itself, but we do it so often that we
have a question mark saying optional regular expression, optional expression.
, we also quite often want to say I want
at least one of something that happens all the time.
So that's exactly the same as writing down R followed
by R star, because this is one followed by at
least zero of them.
But we do it so often that almost every expression
library lets you just write our plus.
And something that is used a great deal is the
single wildcard character.
In most libraries it's a dot.
So full stop doesn't mean full stop.
Full stop means any character.
It gets a little bit more complicated because in programming
languages and text processing.
We often work on a line by line basis, and
quite often we don't actually want to match new lines.
When we write a dot.
So in most libraries, the wildcard means pretty much means
any character except an end of line.
, there are lots and lots more of these.
That's supposed to be wild card.
There isn't yet a green vegetable in regular expressions.
, but the nice thing about regular expressions is that
with this set, you can write quickly and concisely regular
expressions for most things that you're going to meet in
practice.
So all of these things are syntactic sugar.
They don't add any power.
But as I said, modern languages often give you a
great deal extra.
And then there's something I did up there, which I
will explain finally.
In real life, when we match against a regular expression,
we're not usually interested in whether the string matches the
regular expression we want to know does some bit of
the string, because we're searching for something in a bigger
string.
And usually we also want to know what was it
that matched the regular expression we were looking for?
So there are a couple of things you can do
to achieve these aims.
One thing is that in the most implementations, if you
write down a regular expression, then the system automatically assumes
that you meant plus anything before and anything after.
And the way to avoid that happening is usually to
use the carrot and the dollar.
Carrot means beginning of line and dollar means end of
line.
And if you want to know which substring you want
to know, you're looking for a particular regular expression in
a big piece of text, you want to know which
string matched it, and if you have a complex regular
expression, you might not want to know which bits of
your target string match the bits, so you can then
do stuff to them.
So typically we do that by writing brackets around stuff
and then allowing your replacement text to talk about, for
example backslash one or dollar one or something to mean
whatever bit was matched by the first bracket and whatever
bit was matched by the second bracket.
So these again are things that you can learn to
use, and they will save you time in replacing errors
in your code.
, it all gets more complicated.
I'm just about to run out of time.
So the last thing I will mention is one of
the problems is that we've talked about regexp as a
description of non-deterministic automata.
But non-deterministic automata are not real, right?
They don't have a physical meaning.
So programming language is determinism.
If I give you a string a star, a
star, according to the way we've defined things that should
match any string of A's followed by any string of
A's, and it can match it in any way you
.
The first bit could match zero, and the second bit
could match all the A's.
The other way round they could split in the middle
as they choose.
And all of those are good matches.
It's very hard to do text processing if you've got
a huge range of possible matches and you don't know
which one.
So programming languages turn all these non-deterministic things into deterministic
things.
And the way they do that is to say that
this star operator, which is swallowing up input, is what
is called greedy.
So when you see a star, the regular expression matcher
says, I will take as many A's as I possibly
can, and then I will go on and try to
match the rest.
Now that can get complicated, because you might swallow up
a lot of A's, go on and try to match
the rest and find that you can't.
But maybe if you had eaten so many of the
initial A's, you would be able to match the second
half.
So they do backtracking.
They swallow up as much as possible and then look
for the rest of it.
And if that doesn't work, they backtrack one step and
say, I ate too much.
This is going to get a bit unpleasant, isn't it?
If I carry this metaphor forward, , so they backtrack.
If that doesn't work, they backtrack Backtracked further, and that's
an expensive operation.
So in the old days, when computers were slow, it
was possible to write apps that could take noticeable time
to work on some texts.
Then you could rewrite them to work much better.
And there's a whole lot of stuff you can do
to play around with Perl's regex and much more complicated
stuff.
But to be honest, Perl is a write only language.
You can write programs in Perl, but reading them is
a problem and therefore people don't use the fancy stuff.
, when I give the talk about this, I show
you some of the fancy stuff and I have searched
through every piece of code I have in my directory,
which is some 40 years worth of writing code, and
I don't see any instances of any of the complicated
things.
They're just too hard to think about, but they aren't
half fun.
Okay, so that's the end of the core part of
the course.
As I said, I'll stick on the website the plan
for next week's lectures and see you there or not
as you choose.
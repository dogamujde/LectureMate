So, , here's the barcode for work lab.
, it's the same deal.
I can't connect my laptop with a different laptop, but
it still doesn't work.
, so you won't be able to see the lab
results, but you'll be able to take part anyway.
, so go to this URL or scan the code,
please.
Oh, really?
Yeah.
Yeah.
It is.
Is it not working?
I don't see any participants yet.
Have you tried the barcode or the URL up here.
I don't.
Know.
Okay, so it must be a problem on my side.
Let's have a look.
Anyway.
How long do you think you can get rid.
Of.
This.
Pretty good.
Okay.
Can you try now?
Oh, yes.
I can see 29 people.
Great.
Great.
All right, let's get started.
So today's lecture is going to be a bit different
in the sense it's not about language or anything
that.
Not even about categories.
It's about decision making.
So the question is, you know, why would you be
interested in decision making and how does it relate to
the rest of the course?
Well, there's two things.
So one of them is that decision making obviously is
a, , a cognitive task that we face every day.
Right?
We get up, we decide whether to have tea or
coffee for breakfast and so on.
So there's decisions, lots of decisions every day for all
of us.
And it's not even just humans, right?
Animals make decisions all the time.
Should they, should they run away or should they fight
and so on.
And so that obviously is an interesting object of study.
How do these decisions get made?
What are the factors.
What are the mechanisms.
And so on.
So we look at that.
, decisions also have traditionally played a big role in
economics.
So where classical economics has assumed that humans are rational
agents and they behave in an optimal way to do
with, I don't know, maximising the benefit for themselves or
maximising their profit and so on.
And then in the in the 60s and 70s, psychologists
actually started to look at economic decisions.
Should I invest or not?
, and they found that people aren't rational in, in
many ways.
And this is actually a new, relatively new branch of
economics called behavioural economics.
And we'll actually meet a bunch of psychologists who who
were involved in starting this, in particular Daniel Kahneman, who
you might have heard of.
He was a behavioural scientist studying human decision making.
And actually, he died last year.
He's also he was a Nobel Prize winner in economics,
actually.
And people Herbert Simon, who is an AI pioneer
but who was also interested in decision making.
So that's the one thing decisions are interested.
Interesting decisions have an important effect in economics, for example,
where economic outcomes are the sum of lots of individual
decisions.
But there's this other aspect that sometimes humans behave in
a way that is maybe not expected, right?
So far we talked about rules.
These might be logical rules or might be grammatical rules.
We talked about probabilities.
This is Bayes rule or this is conditional probability.
And probability obviously tells you how to behave in some
some sense.
Right.
Bayes rule is a rule for decision making ultimately.
But it turns out that in many ways humans do
not behave in this optimal, rational, ideal way.
And that, again, is something that is an interesting thing
to study.
And so we'll talk about that as well.
And that goes under the moniker of cognitive biases.
And you might have heard about I don't know, the
framing effect or the confirmation bias and stuff this.
So we'll talk about biases this, which people have
also studied quite extensively.
All right.
But let's start with some simple examples.
So judgement is sort of judgement is the process that
leads to decision making right.
So how do you what kind of evidence do you
bring to bear.
And as I've tried to explain, there's decisions all the
time for all of us.
For example next next semester.
Which courses should you take?
Right.
So it's an option of of course it's in second
year.
How do you decide if you play a game chess
go and so on.
There's huge decision space right.
Lots of possible moves.
How do you decide or just simple things to go
to to the shop to buy headphones?
The nicer ones are more expensive.
Is it worth paying the extra money?
That's another decision.
, which factors come into the decision.
So risk for example or reward.
So some decisions are risky.
Let's say we're organising a rescue mission.
there's the risk that more people get injured or
die.
But there's obviously also the reward that we rescue, the
people we're trying to rescue.
How do you weigh up these things?
, I don't know.
The brown thing in the back of your fridge is.
Is it edible?
Is it worth eating?
, in in in a game or in a lottery
or in a prize draw?
How do you decide?
Is this a good, .
Is this a good lottery to play?
Is it worth making a bet?
And so on.
These are sort of fairly isolated artificial types of decisions,
lotteries, for example.
And psychologists and economists, they have studied decision making often
in that setup where there's a the odds of winning
are this.
And what is your decision.
Do you play or not for example, which is sort
of nice in a laboratory setting, but maybe it doesn't
generalise to real life always.
It's also important to note that the information we base
our decisions on are often uncertain, right?
The environment we operate in.
So if I get ill and I ate some food
beforehand, how certain can I be that that's causing it?
It's food poisoning rather than something else.
, if we're, I don't know, doing a drug trial,
for example, how do we figure out if the drug
is effective and nothing will be 100% effective?
And there would always be exceptions.
There would be side effects and so on.
So things are uncertain.
, people don't always tell you what they think.
So I give a presentation.
Do people it?
You know, they say nice things, but do they actually
mean it?
, if I recognise and try to recognise an animal's
or even perceptual decisions that.
Is that a dog or a cat?
Right.
Remember categorisation from Tuesday?
Sometimes it's fuzzy.
Sometimes it's uncertain.
So that's the environment in which decision making happens.
And so the aim now is to understand, explain ideally
even predict human behaviour in these settings, in these settings
of risk and reward that need to be traded off
in the setting of an uncertain environment where I have
some information, but maybe I don't have complete information or
the information isn't entirely reliable.
And in this context, I'd to introduce a framework
that has become quite popular in cognitive science over the
last 20 years or so.
It's called rational analysis.
And the name is slightly misleading because the claim isn't
that human behaviour is always rational and always optimal.
But the claim is that thinking about behaviour in this
way is a useful way of thinking, right?
So if I sit down and I want to analyse
decisions under uncertainty, then I would say I don't know
The optimal strategy would be to maximise the expected gain
or something that.
We'll come to that particular claim.
So that would be sort of the optimal rational, ,
rational strategy.
And then I can study whether people actually apply that
strategy or do they diverge from it in a systematic
way.
And that is interesting.
That is then something I can study separately, I can
maybe formalise.
And the the rational analysis is sort of the assumption
that people are optimal or trying to be optimal.
And then you can study is that actually the case.
How do they deviate.
Maybe it's because of uncertainty.
Maybe it's because of limited memory and so on.
So we can explain that divergence then.
So this is the overall approach.
This is a framework.
If you remember the first was it the first or
the second lecture?
I think the second lecture where we talked about
the taxonomy of cognitive analysis , that was due to,
, Andrea and land.
If I remember correctly, where they had a framework, they
had a theory, they had implementation and so on.
So what we're talking about in terms of rational analysis,
this is a framework.
This is a meta theory in which you can develop
theories okay.
And this was the wrong.
Okay.
So rational analysis goes back to John Anderson who developed
this in the 90s.
And he spelled it out.
But also he actually developed a computational, , it's sort
of a platform, a computational platform in which you can
build, , cognitive models.
This platform is called actor.
You won't this won't be covered in this course.
But if you take a computational modelling course, say in
third year That's something that you'll encounter there.
So it is both a theoretical framework, but also there
is actually a computational modelling environment behind it.
Okay.
So as I said the the starting assumption is assume
what's the optimal way.
What's the rational way of of solving a problem.
So for example we minimise our errors in decision making
or we maximise some form of reward or utility.
It could be just financial gain right.
If it's if it's a financial decision okay.
So we specify these goals that our cognitive system is
is trying to, to achieve.
Then we need to talk about the environment.
As I mentioned often these decisions that happen in an
uncertain environment where some of the information is not reliable
or is incomplete, , and then we can figure out
what kind of assumptions this entails.
So for example, if we're interested in the frequency of
diseases, then maybe sickness is more frequently caused by by
food.
Remember this food poisoning example rather than by social interaction
or social interaction, can lead to transmission of viruses and
so on can also lead to sickness.
In perception we might make assumptions light comes from
above.
That's almost always the case for humans, right?
And for example, in face perception, there's studies that show
if you light a face from from below and from
above, , face perception becomes much more difficult.
So that seems to be an inbuilt assumption in communication.
People normally do say things in order to be informative
rather than to deceive or to mislead.
And then we also need to think about computational limitations.
Right.
So we started with this sort of rational assumption here
at number one.
Then we looked at the environment, which limits how rational
we can do.
We can be.
And we also need to look at computational limitations.
So we can probably not consider all possible hypotheses.
Right.
In particular, if it's a very large hypothesis space we
have limited memory as well.
We forget stuff all the time.
Perception comes with inaccuracies.
We don't always perceive things correctly and so on.
So there is that additional problem that we need to
take into account, which again might explain that sometimes our
decisions are not 100% rational.
And as I said, Herb Simon is one of the
other pioneers here.
And he says that rational behaviour is compatible with access
to information and the computational capacities that the the agent
or the organism possesses.
And he calls this bounded rationality.
Right.
So we are rational within reason, right within the bounds
of our memory and computational limitations, for example.
And so now we have made all these assumptions.
And now we can start to formalise this.
Right.
We can, for example, say okay we'll apply Bayes rule
or some other form of probability theory.
Today we'll look at simple things , expected utility.
, and then we can see whether this behaviour, the
purportedly optimal behaviour corresponds to what we find experimentally when
we study humans.
As I said, this is a framework.
This is not a theory by itself.
It's a framework for building theory.
Sort of a meta, a meta, a meta theory in
some sense.
And then once you have worked this out and you've
written down a nice sort of mathematical formulation for your
theory, then you can think about implementation, right?
How do we build a computational model then.
And, , yeah, as I said, Russian analysis itself is
not constrained enough to, to, , to be a theory.
And often also there's limitations that are not being made
explicit, in particular computational limitations.
Most people don't talk about memory limitations and things
that.
And then yeah, we based on that, we can now
look at the differences between this optimal or rational behaviour
and the behaviour we see in real, , experimental participants.
Right.
, there's other things that can go wrong.
People might make assumptions or have tacit expectations.
They might solve a different problem from what the experimenter
thinks they're doing.
The optimal solution might exist, but it might not be
computational feasible.
So that's again the limitations.
And, , some tasks maybe people are just not adapted
to because they're, , it's not a task that they
have encountered before.
Okay.
So now with that in mind, we look at some
of these, , supposed deviations from rational behaviour.
And these are often called heuristics or biases in the
literature.
, so and they defined as departures from, , normative
rational theory.
So you say, you're saying, for example, according to Bayes
rule, you should behave this according to conditional probability.
You should do this according to I don't know, minimum
description.
Length is something else we've encountered.
This should be the optimal solution.
But people behave differently, right?
So that would be something we need to explain.
And biases are a deviation from rational behaviour for example
from probability theory.
And heuristics are simple strategies that give you fast solutions,
maybe without considering all, all possible or relevant evidence.
Okay, so both types of things can exist.
So there is unfortunately a slight overloading of the term
bias here.
So we've talked about cognitive biases so far.
So if you remember we talked about word acquisition and
the I don't know mutual exclusivity bias or the whole
world whole word bias that helps children acquire words in
an uncertain environment.
So this is a different type of bias.
It's more a heuristic that allows you to prioritise
certain certain hypotheses.
Right.
So in this case, for example, the hypothesis that a
new word refers to a new object rather than being
a synonym for another object you know already.
Okay.
So, , the, the biases that we've talked about so
far, they're sometimes called inductive biases, a bit in
machine learning where algorithms have inductive biases.
Now we're going to talk about the cognitive biases by
which we mean the deviations from optimal or rational behaviour
okay.
So there's an ambiguity in the term here.
Unfortunately the the inductive biases are a bit related to
heuristics but not exactly the same.
Okay.
So with that in mind here are some some of
these cognitive biases framing effect.
We'll talk about that today.
And then tomorrow we'll talk about the representative representativeness bias,
the availability bias and the base rate neglect.
And we look at how these have informed models
of decision making.
And today we're looking at one particular model.
This is the model called prospect theory, which goes back
all the way to the 80s to work of Trotsky
and Kahneman on economic decision making.
Okay.
And let's start with an example.
And this is hopefully.
So if you haven't signed up for War Club yet,
now's the time.
Okay.
So you should be able to see the question now
on your device.
Yes.
, this is a simple , a simple lottery type
decision.
A game of chance.
Right.
You have two possible choices.
Option one is a 25% chance of winning £3,030.
And option two is a 20% chance of winning £45.
And I this is the wrong slide.
I'm so sorry.
Sorry.
This is the first one.
, so option one is a sure win of £30,
and option two is 80% chance of winning 30, £45.
So which do you choose?
To.
So not everyone has voted yet.
, 30s.
Before we look at the results.
Okay.
So I can't give you the results.
, well, I'll give you the results because you can't
see them on the screen, so.
Option one.
65% of you have chosen option one.
I'm sure we know £30.
35% of you have chosen option two.
80% win or £45.
, so the correct answer, the normally normatively correct answer
is two actually, which is the one that only a
third of you have chosen.
Can anyone explain why they've chosen what they've chosen?
Just sort of show of hands.
Who would to justify.
Yeah.
Down there.
Because if I chose the 80% one, I'd be so
much more upset if I got nothing.
Yes, that's a good point.
People certainty.
.
Anyone chosen option two?
The expectation value is higher.
Yeah.
So if you just compute the expectation value, which is
maybe something you remember from, , when when you did
some probability theory, hopefully in high school or something
that, you just multiplied the, the gain times the probability.
And this is actually slightly higher for option two.
So if you go in terms of expected value.
So how much am I going to win on average
with this bet.
Then bet two is better.
But most people choose bet one anyway, as your colleague
said, because it has this nice feel of a certain
win.
And that's that's definitely something to be happy about.
So that's already an indication that people are maybe not
super rational in decisions this.
Let's look at another similar one.
So now the option one is 25% chance of winning
£30, and a 20% chance of winning £45.
Now which one do you go for?
1 or 2.
So no more certain wins in this example.
Okay.
Most people have voted.
Did.
So let's have a look.
Okay.
So now the outcome is option 130% and option 270%.
So it's the other way around.
Why do people think that is.
Why do people option two more.
Any any hands?
Yeah I don't know.
This is exactly the same as the first question.
It's still 20% plus likelihood one.
Yes.
It's the same thing.
So this is the same as the first question.
But this time there's no certainty.
So people are biased in this situation.
Yeah.
That's the that's the that's a good explanation.
So now if we compute the expected value right.
Just multiply the probability times the the gain then that
is 7.5.
In option one and nine in option two.
So in terms of expected gain option two is clearly
better.
And because there isn't this bias towards going for the
certain option, which we had in the previous example, people
will go for the expected the expected gain.
I mean, also maybe because I explained it after the
first example that you can you can think about this
in terms of expected gain or expected utility.
All right.
So that was a really simple example.
And now let's look at slightly more complicated ones in
order to talk about the framing effect.
So for this we're using what's called the conjoint bet.
And this is Kahneman who invented this or well at
least published about it.
So now we have two beds together and things become
more complicated.
Right.
Because okay, one of them might be certain, but the
other one might not be certain.
And in this example, the problem is also that the
first bet is about wins, and the other bet is
about losses.
So now we can use this to study how people
trade off wins and losses.
Okay, this is our first bet.
And this time, you don't need to vote.
It's a sure win.
Of £240.
Or second choice 25.
25%.
Chance of winning £1,000.
And of course, 75% chance of winning nothing.
And in conjunction.
So you need to bet.
In both cases, the second bet is you have a
sure loss of £750, or you have 25% chance of
losing nothing.
And 75% chance of losing £1,000.
Okay, so this is, as I said, joint bet.
You need to make both beds.
And the first one is about wins and the other
one's is about losses.
Again we have a certain win and a certain loss.
, and , people then they have four outcomes, right?
They can do a and c a and d b
and c or b and d.
So these are the possible choices here.
The possible combined bets or joint bets.
And now the question is what do people do.
Right.
This is a more complicated situation.
And maybe people find it harder to work out the
expected value and so on.
So this is an example that is taken from this
paper by by Trotsky and Kahneman, which I've already said
as a reading for today.
This is a fun paper.
So have a look.
It's really old right from the 80s, but it's the
definition of a classical paper.
And it's what started prospect theory, which is still a,
you know, an important and influential theory in behavioural economics.
And it's also what won them the Nobel Prize.
Well, Trotsky had already died, unfortunately, when Kahneman got the
Nobel Prize.
Anyway, okay, so let's look at this scenario here.
So first of all, let's think about what we can
expect people to do.
So maybe they're computing expected values, just we discussed
in the simple example of a single bed.
But maybe they're using something simpler, right?
They take the best, best case and the least bad
worst case.
So what would that mean here?
So the best best case would be you win £1,000
right.
So that's a lot of money.
So maybe people go for that.
And then the least worst worst case.
So here the worst case is you lose a £1,000.
So maybe then you go for this lose 750 because
this is certain.
But at least it's not the worst case.
That would be a possible heuristic.
, and .
Of course we can just ask people and see what
pattern we get.
Okay.
But let's quickly look at expected utility.
First.
That's the the third option here.
For both cases, they people choose the, the outcome
with the best expected value.
And just to formalise this with informally already talked about
this, let's have a bet that has a number of
outcomes or 1 or 2 to o n.
And then the expected utility is the sum over all
the outcomes of the probability of the outcome times the
utility of that outcome.
And utility is a function that , we can basically
that's a parameter, right?
We don't have to define utility as, you know, the
direct monetary value initially.
That's what we're going to do.
But it turns out that's actually not a not the
correct definition okay.
So always the utility.
So the important question is how do we define, ,
the utility of all.
Oh, let's assume it's simply the monetary value.
So the utility of losing £750 would be -750.
The utility of winning £240 would be 240.
And so if we have 25% chance of winning 1,075%
chance of winning nothing, then the utility would be 0.25
times 1000 plus zero point plus 0.75 times zero 250.
So that would be the expected utility of.
.
Option B here, right.
And so we can compute this for all the for
all the possible options.
, but we already saw that people maybe don't always
look at utility.
So for example, they certainty even if it might
not be optimal in terms of expected utility.
, also, if we are assuming this, then we're assuming
that, , it's sort of a linear function, right?
The utility grows linearly with the amount of money.
So that would mean a win of 1000 of £100
is ten times as good as a win of £10.
Right.
Is this actually the case and a win of, I
don't know, a million would be 100,000 times better than
a win of £10 and so on.
So do people actually make this assumption.
So that's one question.
, and if we think about it, we can see
that there's actually already reason, you know, just intuitively there's
reason to believe that maybe that's not the whole story,
right.
So people sometimes make decisions that are inconsistent with utility.
So for example insurance.
Right.
They want to spend a small amount of money to
reduce the risk of losing something.
, the.
As we've already seen a certain gain, a guaranteed gain
of £10 might be better than 50% chance of winning
£20, even though the expected utility is the same.
Right.
It's £10 in both cases.
And if you look at studies of how happy people
are with their lives, then you can see as people
get richer, they get happier.
But it's not a linear function and flattens off at
some point.
Right.
If you, , if you're a millionaire, then I don't
know.
The difference between 1 million and 10 million might be
big, but the difference between 100 million and 110 million
might not be so big.
Okay, so it seems to be that it's not a
linear function, expected utility in happiness, but it sort of
flattens off after a while.
But what about lottery tickets?
Right.
The the expected value of a lottery is always negative
because lotteries are designed so that the person who runs
the lottery wins.
But people play anyway.
So why is that?
That's so.
Yeah.
This already sheds doubt until the simple assumption of expected
utility.
But let's go back to this example.
This was our example with the joint bet.
You have to choose one of A or b and
one of the C or d.
What do people actually do.
Well let's look at the.
Two choices A and D.
Right.
A is a sure win of 240.
And D is a 25% of chance of losing nothing.
75% of chance of losing a thousand.
That's actually what most people prefer.
In this study it's 73% of participants.
, and compare this to B and C.
B is 25% chance of winning 1,070%, 75% chance of
winning nothing and 25% chance of losing nothing.
75% chance of losing 1000.
So if we actually compute the expected utility, then the
expected utility of A is better than expected utility of
B and the expected utility of A of D.
Sorry, A is worse than B, and D is worse
than C.
So people actually in both cases for bet one and
bet two pick an option that's strictly worse than the
optimal one based on expected utility.
All right.
So now the question is why is this.
, however, if you actually give them the expected value
you say this bet is the follows is as follows
as following.
And the expected value is 240.
And this bet has an expected value of 250.
Then 100% of the people Choose the correct or the
normatively correct answer.
Right.
So if you give it, if you give people this,
then they choose A and A and C.
If you give people these numbers here in blue and
red as well, then they actually choose B and C,
right, rather than a and D.
So that means they're not normally computing a utility, right.
If you give it to them they use it, but
they don't sort of voluntarily use it.
If it's not given they might not compute utility okay.
So they they pick the worse options.
And this doesn't seem to depend on the utility function
in the paper by trust and Kahneman.
There's other examples where we see this behaviour.
Also it's a question in terms of you can rescue
300 people with 25% chance, or you can rescue 600
people with a 10% chance.
So questions this, you get the same outcome.
So and the theory that they're advancing is called prospect
theory.
And it explains things in a number of ways with
a number of assumptions.
So there's three key ideas that you need to need
to assume.
So first of all, , we need to forget this
assumption that gains and losses are equally bad, right?
So, , this sorry, I'm getting ahead of my time.
So this is called loss aversion.
, gains diminish more quickly.
, losses are more important.
So if we draw this as a graph where we
have the outcome here on the x axis and the
value on the y axis, then first of all, we
see it's not linear, right.
So the more we gain the less value we
attach to it, the less important it becomes.
This is the example of if if you have, ,
if you have 100 million, then, , gaining another 10
million, it's not going to be a big difference.
So this flattens out rather than being linear.
Right.
If it was just expected utility then this would be
a straight line.
And on the other hand the losses also flatten out
but less quickly.
Right.
So it's more linear here at least initially for the
losses.
So you can caricature this and say losses hurt more
than gains make you happy right.
If you lose the same amount then this hurts more
than winning the same amount makes you happy.
So let's assume, I don't know, £10 somewhere here, then
that makes you happy.
But , it's similar in terms of loss, but £100
is somewhere here, and the loss of £100 is worse
than the gain of £100.
Okay.
And this is something that's called loss aversion, right?
You try to avoid losses.
Losses hurt more than than gains make you happy.
, there's the the fact that they're not not linear,
neither gains or losses.
Right.
Otherwise this would be a straight line.
So instead it's a curve here.
The more you gain or the more you lose.
It loses its potency.
And then a third assumption that you can't read off
the the function here is that we overvalue improbable events.
And that's something we will come back to next time
that things that are very probable but somehow memorable, we
assign them a higher probability than we actually should.
plane crashes or winning the lottery?
Really unlikely, but also very shocking.
So it's our memory that is playing a role here
and is giving us a and making us overestimate the
probability of improbable events.
Okay, so how does this work in practice.
So first assumption diminishes diminishing value to gains and losses.
So if U is our utility function and u of
X is A is now not the expected value but
the subjective value right for us as human beings.
Then according to this, a win of £120 minus a
loss of £110 is a less a has lower utility
than a gain of 20, minus a loss of ten,
a gain of ten.
Right.
This is because these are larger amounts.
Right.
The difference is £10 in both cases here and here.
But here is larger amounts.
And if we go back to our curve here then
that means we are somewhere here.
So the extra £10 don't make a big difference.
But if we're looking at the right side of the
inequality, then we're somewhere here and the extra £10 make
a difference.
Okay.
Because it's not a linear function.
So that's one thing that prospect theory assumes.
And the other thing is that, as I said, loss
aversion losses hurt more than gains.
So the utility of winning £100 is not the same
as the negative utility of losing £100.
Right.
So because with a £100 gain, we're somewhere here, let's
say.
And with a £100 loss we're somewhere here.
So it's a bigger.
Utility than the £100 gain.
And then the improbable events I already mentioned that.
So this is why people play lotteries, which is why
people take risky opportunities to avoid losses.
This is also gamblers have the tendency they've they've lost
a lot of money and then they take a really
high risk bet to win the money back.
Because the losses are the losses hurt much more than
than the gains.
And so they're willing to overestimate the probability.
In in the formulation of prospect theory they introduce a
weighting function pi to model this.
So this wouldn't be in wouldn't be part of the
utility function that we have here.
It's a separate mechanism that you need to assume.
Okay.
So let's try to sort of test our intuitions.
regarding prospect theory.
So what kind of things would you want to.
Would you be able to explain.
And there's a short quiz.
Okay.
So according to prospect theory which of the following statements
should be true.
So statement one if you have £1,000, then winning £10
is not a big deal.
If you have £20, then losing £10 is not a
big deal.
Losing £200 has a bigger effect than winning to £100.
If you have £1,000, you are prone to take a.
If you've lost £1,000, then you're prone to take a
risky gamble to win it back.
Or finally, people react more strongly to sure losses and
to sure gains.
So which of these is true according to prospect theory?
To be able to.
Do this.
Okay.
We have 41 votes.
Maybe a few more.
Give you another minute.
Okay, let's have a look.
Number one.
, 78% of you think that's correct.
If you have £1,000 in winning.
, £10 is not a big deal.
Why is this?
Does anyone.
Would anyone to explain?
So this is this idea that, .
The value of of both gains and losses diminishes the
bigger they get.
Right.
So this is why our function here is not a
linear function.
So we will be somewhere up here where we've already
won £1,000 and then move a bit more to the
right.
It doesn't make a big difference in terms of our
perceived value or utility.
Okay.
So that's correct.
Number two.
Only 10% of you think that if you have £10,
then losing.
Sorry.
If you have £20, then losing £10 is not a
big deal.
So that means you would be somewhere here and then
you go down from 20 to 10.
This is where the curve is almost linear still right
in this small section here.
So that's not correct according to prospect theory.
, so it is a big deal if you're starting
at this small amount.
So that's correct.
Then the next one.
96%.
So losing £200 has a bigger effect than winning to
£100.
Yeah.
This is the loss loss aversion right.
So let's assume the £200 are somewhere here then losing
£200 or somewhere here.
It's it can still get a lot worse right.
So losses hurt more than, than gains.
So that's also true according to prospect theory.
Then number four.
, if you have £1,000, then you are prone to
take a risky gamble to if you lost £1,000, then
you're prone to take a gamble to to win it
back.
That is not here in the diagram.
But is this assumption that people overweight improbable events and
because losses hurt a lot.
Right.
So we've lost £1,000.
, then we're willing to take this gamble even though
it's it might have a low probability.
, this is helped by the fact that we overweight
improbable events, right?
I don't know, I'm in a casino, and I play
roulette, and I bet on number seven.
Then that's really, you know, one inch 36 or something
is the probability of winning.
But my loss has hurt a lot.
And I'm overweighting the the rare event of getting a
seven.
And so I go for the gamble anyway.
So that's also explained by prospect theory and the final
one.
People react more strongly to sure gains and sure losses
as we saw initially.
Anything that's sure is is good and people prefer it.
But at the same time, , losses hurt more than
gains.
So, , that also predicts that people should find sure
losses even more.
Effective than short gains okay.
Because first of all, both things, let's assume both things
are certain then, given that losses hurt more.
Sure, losses are even even worse.
So that also follows from prospect theory.
Okay.
That was it.
So I have a short summary.
We looked at rational analysis as a framework for modelling
cognition.
The idea was basically you work out what would be
the rational behaviour.
So for example in the examples we've seen, the rational
behaviour would be to compute the expected value based on
probability theory.
It turns out that people don't behave in that way
if we give them actual decisions to make.
So rational analysis can be applied to human decision making
and shows where the two diverge, the actual behaviour and
the the supposed optimal behaviour.
And we've looked at some classic experiments.
So for example, the joint bets that we saw and
the way the problem is framed makes it makes a
big difference, right.
Whether I give people the expected value or I just
give them the probabilities.
We've seen that.
Losses and gains.
They don't grow linearly.
They flatten out after a while as the gains get
bigger or the losses get bigger, you care less.
, losses hurt more than than gains benefit you.
So they have a bigger effect than gains.
And we tend to overestimate the probability of rare events,
things train crashes and lottery wins and so on.
And we've seen prospect theory, which I've not made mathematically
precise, but given you an intuition of how prospect theory
accounts for that sort of behaviour.
And if you look at the article by Trotsky and
Carol Monday, they explain it in more detail.
They give a lot more examples.
And we have two minutes for questions if there are
any questions.
Okay.
See you tomorrow.